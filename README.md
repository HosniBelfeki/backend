# ğŸ”§ Backend - Assistant de Codage IA

API REST construite avec FastAPI et intÃ©gration OpenAI pour les fonctionnalitÃ©s d'intelligence artificielle.

## ğŸš€ DÃ©marrage rapide

```bash
# CrÃ©er l'environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou venv\Scripts\activate  # Windows

# Installation des dÃ©pendances
pip install -r requirements.txt

# Configuration
cp .env.example .env
# Modifier .env avec vos clÃ©s API

# DÃ©marrage du serveur
python main.py
```

## ğŸ“¦ Technologies utilisÃ©es

- **FastAPI** - Framework web moderne et rapide
- **OpenAI API** - Intelligence artificielle
- **Pydantic** - Validation des donnÃ©es
- **Uvicorn** - Serveur ASGI
- **Python 3.11+** - Langage de programmation

## ğŸ—ï¸ Structure

```
â”œâ”€â”€ main.py              # Application FastAPI principale
â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â”œâ”€â”€ .env.example         # Template de configuration
â”œâ”€â”€ render.yaml          # Configuration Render
â””â”€â”€ Dockerfile           # Image Docker
```

## âš™ï¸ Configuration

### Variables d'environnement (.env)
```env
OPENAI_API_KEY=sk-...                    # ClÃ© API OpenAI (obligatoire)
OPENAI_API_BASE=https://api.openai.com/v1
HUGGINGFACE_API_KEY=hf_...              # ClÃ© API HuggingFace (optionnel)
HOST=0.0.0.0
PORT=8000
```

### ModÃ¨les supportÃ©s
- **OpenAI** : gpt-4.1-mini, gpt-4.1-nano, gemini-2.5-flash
- **HuggingFace** : bigcode/starcoder

## ğŸ”Œ Endpoints API

### `POST /generate`
GÃ©nÃ©ration de rÃ©ponses IA gÃ©nÃ©riques.

### `POST /explain`
Explication dÃ©taillÃ©e du code.

### `POST /refactor`
Refactorisation du code.

### `POST /generate-code`
GÃ©nÃ©ration de code basÃ©e sur une description.

### `POST /detect-bugs`
DÃ©tection de bugs potentiels.

### `POST /optimize`
Optimisation du code.

### `GET /docs`
Documentation interactive Swagger UI.

## ğŸ”’ SÃ©curitÃ©

- **CORS** configurÃ© pour les domaines autorisÃ©s
- **Validation des entrÃ©es** avec Pydantic
- **Gestion des erreurs** centralisÃ©e
- **Rate limiting** (recommandÃ© pour la production)

## ğŸš€ DÃ©ploiement

### Render (recommandÃ©)
Le fichier `render.yaml` configure automatiquement le dÃ©ploiement.

### Docker
```bash
docker build -t ai-coding-assistant-backend .
docker run -p 8000:8000 \
  -e OPENAI_API_KEY=votre_clÃ© \
  ai-coding-assistant-backend
```

### Manuel
```bash
uvicorn main:app --host 0.0.0.0 --port 8000
```

## ğŸ“Š Monitoring

### Logs
Les logs sont automatiquement gÃ©nÃ©rÃ©s par Uvicorn et FastAPI.

### Health Check
Endpoint `/` pour vÃ©rifier l'Ã©tat du service.

### MÃ©triques
- Temps de rÃ©ponse API
- Utilisation des tokens OpenAI
- Taux d'erreur

## ğŸ”§ DÃ©veloppement

### Mode debug
```bash
uvicorn main:app --reload --log-level debug
```

### Tests (Ã  implÃ©menter)
```bash
python -m pytest tests/
```

### Ajout d'endpoints
1. CrÃ©er le modÃ¨le Pydantic
2. ImplÃ©menter la fonction
3. Ajouter la route FastAPI
4. Documenter l'endpoint

